{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hann ablak\n",
    "  * Paraméterek:\n",
    "       * M: pontok száma\n",
    "  * Visszatérés:\n",
    "       * ndarray, M*1-es mátrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft, fftshift\n",
    "\n",
    "Hann_window = np.hanning(512)\n",
    "plt.plot(Hann_window)\n",
    "plt.title(\"Hann window\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.show()\n",
    "\n",
    "np.fft.rfft(window).size\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import wave\n",
    "import numpy\n",
    "import scipy.io.wavfile\n",
    "\n",
    "wav1 = scipy.io.wavfile.read(\"D:/Doma/bd/train/wav/2015-05-04-Ma-reggel---51--rész---07-26--07-36_FarkasAdam_0092.wav\")\n",
    "wav_withwav = wave.open(\"D:/Doma/bd/train/wav/2015-05-04-Ma-reggel---51--rész---07-26--07-36_FarkasAdam_0092.wav\",\"r\")\n",
    "print(wav_withwav.getparams())\n",
    "data = wav1[1]\n",
    "data.size\n",
    "data[4]\n",
    "\n",
    "window = data\n",
    "plt.plot(window[90000:96255])\n",
    "plt.title(\"Hangnyomás karakterisztika\")\n",
    "plt.ylabel(\"Hangnyomás\")\n",
    "plt.xlabel(\"Minta\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wav beolvasása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import wave\n",
    "import numpy\n",
    "import scipy.io.wavfile\n",
    "\n",
    "wav1 = scipy.io.wavfile.read(\"D:/Doma/bd/train/wav/2015-05-08-Ma-délelőtt---55--rész--2015---12-44--12-54_BernathBernadett_0020.wav\")\n",
    "wav_withwav = wave.open(\"D:/Doma/bd/train/wav/2015-05-08-Ma-délelőtt---55--rész--2015---12-44--12-54_BernathBernadett_0020.wav\",\"r\")\n",
    "print(wav_withwav.getparams())\n",
    "data = wav1[1]\n",
    "data.size\n",
    "data[4]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "window = data\n",
    "plt.plot(np.absolute(processed_data[0.006]))\n",
    "plt.title(\"spektrum\")\n",
    "plt.ylabel(\"Amplitúdó\")\n",
    "plt.xlabel(\"Frekvencia\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kész program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from collections import OrderedDict\n",
    "import h5py\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konstansok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_delay = 0.09 # a felső hálózat a fájlok első 90 ms-át levágja\n",
    "sample_rate = 16000\n",
    "frame_size = 512\n",
    "frame_shift = 256\n",
    "\n",
    "num_of_wav= 600\n",
    "\n",
    "mlf_train = \"train.mlf\"\n",
    "mlf_eval = \"eval.mlf\"\n",
    "\n",
    "root_train = \"D:/Doma/bd/train/wav/\"\n",
    "root_eval = \"D:/Doma/bd/eval/wav/\"\n",
    "\n",
    "hdf5_train = \"D:/Doma/bd/train_data.hdf5\"\n",
    "hdf5_eval = \"D:/Doma/bd/eval_data.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hann ablak\n",
    "  * Paraméterek:\n",
    "       * M: pontok száma\n",
    "  * Visszatérés:\n",
    "       * ndarray, M*1-es mátrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hann_window = np.hanning(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier transzform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fourier(data):  \n",
    "    processed_data = OrderedDict()\n",
    "    processed_data = {float(\"{0:.3f}\".format(i*(1/sample_rate)-t_delay)):\n",
    "                      np.abs(np.fft.rfft(data[i:i+frame_size-1]*Hann_window[i%frame_size])) \n",
    "                      for i in range(int(sample_rate*t_delay), data.size-frame_shift, frame_shift)}\n",
    "    processed_data.popitem()\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fájlkezelés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def openwav(file_name, root_name):\n",
    "    wav_file = root_name+file_name.rstrip(\"\\n\").strip(\"\\\"\") +\".wav\"\n",
    "    wav1 = scipy.io.wavfile.read(wav_file)\n",
    "    \n",
    "    return wav1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_HDF5(in_put, output, hdf5_name , k):\n",
    "\n",
    "    data_file = h5py.File(hdf5_name, 'a')\n",
    "    data_file.create_dataset('input{}'.format(k), data=in_put)\n",
    "    data_file.create_dataset('output{}'.format(k), data = output)\n",
    "    data_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# két halmazra külön paraméterezhetőség !!!\n",
    "def from_hdf5(hdf5_name, k):\n",
    "    filename = hdf5_name\n",
    "    # Get the data\n",
    "    f = h5py.File(filename, 'r')\n",
    "    i_data  = np.array(f[\"input0\"])\n",
    "    o_data = np.array(f[\"output0\"])\n",
    "\n",
    "    for i in range(1,k):\n",
    "        i_data = np.concatenate((i_data, np.array(f[\"input{}\".format(i)])), axis=0)\n",
    "        o_data =np.concatenate((o_data, np.array(f[\"output{}\".format(i)])), axis=0)\n",
    "    f.close()\n",
    "    return i_data, o_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A tanító adatok előkészítése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output előkészítése: követelmények (Keras) -->ndarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input előkészítése: követelmények (Keras) --> ndarray matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finalize_io(spectrum, output_data):\n",
    "    in_put = np.array([i for i in spectrum.values()])\n",
    "    in_put /= np.amax(in_put)\n",
    "\n",
    "    # 0 = \"silence\" , 1 = \"noise\"\n",
    "    for n, i in enumerate(output_data):\n",
    "        if(i == '<sil>'):\n",
    "            output_data[n] = 0\n",
    "        else:\n",
    "            output_data[n] = 1 \n",
    "    output = np.array(output_data)\n",
    "    \n",
    "    return in_put, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train=True):\n",
    "    \n",
    "    if train:\n",
    "        mlf_name = mlf_train\n",
    "        root_name = root_train\n",
    "        hdf5_name = hdf5_train\n",
    "        \n",
    "    else:\n",
    "        mlf_name = mlf_eval\n",
    "        root_name = root_eval\n",
    "        hdf5_name = hdf5_eval\n",
    "    try:\n",
    "        os.remove(hdf5_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    l = 0\n",
    "    # number of wav counter\n",
    "    k = 0\n",
    "    output_data = []\n",
    "    \n",
    "    with open( mlf_name, encoding=\"ansi\", errors=\"ignore\") as f:\n",
    "        for i in f:\n",
    "        # fájl címének beolvasása\n",
    "            if(i[0] == \"\\\"\"):\n",
    "                data = openwav(i, root_name)\n",
    "                spectrum = fourier(data)\n",
    "                keys = [i for i in spectrum.keys()]         \n",
    "            if(i[0] != \"#\" and i[0] != \"\\\"\" and i != \".\"):\n",
    "                temp = i.split()\n",
    "                while l < len(keys):\n",
    "                    half = float(\"{0:.3f}\".format(keys[l]+frame_shift/sample_rate))\n",
    "                    if float(temp[0])<=half<=float(temp[1]):        \n",
    "                        l += 1\n",
    "                        output_data.append(temp[2])\n",
    "                    if half>float(temp[1]):\n",
    "                        break\n",
    "\n",
    "            if(i == \".\\n\"):\n",
    "                in_put, output = finalize_io(spectrum,output_data)\n",
    "                to_HDF5(in_put, output, hdf5_name, k)\n",
    "                l = 0\n",
    "                k += 1\n",
    "                output_data = []\n",
    "                if k == num_of_wav:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adatok  beolvasása (HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from hdf5 paraméterének meg kell egyeznie process data paraméterével!!!\n",
    "i_data, o_data = from_hdf5(hdf5_train, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evi_data, evo_data = from_hdf5(hdf5_eval, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(191588, 256)\n",
      "<class 'numpy.ndarray'>\n",
      "(191588,)\n"
     ]
    }
   ],
   "source": [
    "print(type(i_data))\n",
    "print(i_data.shape)\n",
    "\n",
    "print(type(o_data))\n",
    "print(o_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(17478, 256)\n",
      "<class 'numpy.ndarray'>\n",
      "(17478,)\n"
     ]
    }
   ],
   "source": [
    "print(type(evi_data))\n",
    "print(evi_data.shape)\n",
    "\n",
    "print(type(evo_data))\n",
    "print(evo_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2k+1 frame összekapcsolása\n",
    "\n",
    "   * A szavakon belüli szünetek által okozott hiba enyhítésére konkatenálunk 2k+1 bemenetet (n-k,...,n,...,n+k), de a kimenet hasonlóképpen az n elem kimenete lesz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "l = 0\n",
    "\n",
    "ex_i_data=numpy.zeros(i_data.shape[0]-2*k, 256*(k+1))\n",
    "\n",
    "for i in i_data():\n",
    "        i\n",
    "        if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network\n",
    "   * Simple fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kimeneti típusok száma\n",
    "num_classes = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# a kimenetet megfelelő formátumra hozzuk (shape = (count frame,classes))\n",
    "# output = keras.utils.to_categorical(output, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 35,901\n",
      "Trainable params: 35,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(256,), kernel_initializer='uniform', activation='relu'))\n",
    "# model.add(Dense(100, kernel_initializer='uniform', activation='relu'))\n",
    "# model.add(Dense(100, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(100, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer=\"uniform\", activation = 'relu'))\n",
    "model.summary()\n",
    "# model.add(Dense(8, init='uniform', activation='relu'))\n",
    "# model.add(Dense(2, init='uniform', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191588 samples, validate on 17478 samples\n",
      "Epoch 1/20\n",
      "3s - loss: 0.4158 - acc: 0.8543 - val_loss: 0.5140 - val_acc: 0.8809\n",
      "Epoch 2/20\n",
      "3s - loss: 0.3742 - acc: 0.8981 - val_loss: 0.4162 - val_acc: 0.8855\n",
      "Epoch 3/20\n",
      "3s - loss: 0.3253 - acc: 0.8998 - val_loss: 0.3642 - val_acc: 0.8857\n",
      "Epoch 4/20\n",
      "3s - loss: 0.3097 - acc: 0.9015 - val_loss: 0.3626 - val_acc: 0.8865\n",
      "Epoch 5/20\n",
      "3s - loss: 0.3045 - acc: 0.9016 - val_loss: 0.3610 - val_acc: 0.8862\n",
      "Epoch 6/20\n",
      "3s - loss: 0.3007 - acc: 0.9017 - val_loss: 0.3605 - val_acc: 0.8868\n",
      "Epoch 7/20\n",
      "3s - loss: 0.3409 - acc: 0.8825 - val_loss: 0.4177 - val_acc: 0.8827\n",
      "Epoch 8/20\n",
      "3s - loss: 0.3137 - acc: 0.9009 - val_loss: 0.3478 - val_acc: 0.8858\n",
      "Epoch 9/20\n",
      "3s - loss: 0.3447 - acc: 0.8794 - val_loss: 0.4956 - val_acc: 0.8757\n",
      "Epoch 10/20\n",
      "3s - loss: 0.3262 - acc: 0.8996 - val_loss: 0.3787 - val_acc: 0.8856\n",
      "Epoch 11/20\n",
      "3s - loss: 0.3467 - acc: 0.8835 - val_loss: 0.3990 - val_acc: 0.8837\n",
      "Epoch 12/20\n",
      "3s - loss: 0.3045 - acc: 0.9008 - val_loss: 0.3751 - val_acc: 0.8856\n",
      "Epoch 13/20\n",
      "3s - loss: 0.2987 - acc: 0.9011 - val_loss: 0.3520 - val_acc: 0.8857\n",
      "Epoch 14/20\n",
      "3s - loss: 0.3202 - acc: 0.8959 - val_loss: 0.3637 - val_acc: 0.8862\n",
      "Epoch 15/20\n",
      "3s - loss: 0.3071 - acc: 0.8980 - val_loss: 0.3538 - val_acc: 0.8847\n",
      "Epoch 16/20\n",
      "3s - loss: 0.3022 - acc: 0.9003 - val_loss: 0.3618 - val_acc: 0.8853\n",
      "Epoch 17/20\n",
      "3s - loss: 0.2908 - acc: 0.9018 - val_loss: 0.3625 - val_acc: 0.8856\n",
      "Epoch 18/20\n",
      "3s - loss: 0.2958 - acc: 0.9019 - val_loss: 0.3665 - val_acc: 0.8839\n",
      "Epoch 19/20\n",
      "3s - loss: 0.3207 - acc: 0.8873 - val_loss: 0.3684 - val_acc: 0.8849\n",
      "Epoch 20/20\n",
      "3s - loss: 0.3083 - acc: 0.9026 - val_loss: 0.3614 - val_acc: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be0d540ba8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tanítás\n",
    "model.fit(i_data, o_data, epochs=20, batch_size=200,  verbose=2, validation_data=(evi_data, evo_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.361406003308\n",
      "Test accuracy: 0.88385398787\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(evi_data, evo_data, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(256,)))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "#paraméterek száma\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(i_data, o_data,\n",
    "                    batch_size=30,\n",
    "                    epochs=22,\n",
    "                    verbose=1,\n",
    "                    validation_data=(evi_data, evo_data))\n",
    "\n",
    "score = model.evaluate(evi_data, evo_data, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
